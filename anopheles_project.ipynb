{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Malaria Classification on Blood Cells images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a work in progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitted the dataset to 3 sets for training, testing and validation. validation is 0.1 of the entire data. The rest was splitted 0.8 and 0.2 respectevily\n",
    "Made several tuning.\n",
    "The simplicity of the model and task is great for everyone to learn pyTorch and get intuitation about DNN and this dataset. So everyone are welcomed and get interested about this toy and wonderful dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "any error in the code is mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################                                \n",
    "#\n",
    "#         Anopheles Project\n",
    "#        Detecting malaria in blood cells images\n",
    "#       Done by Efi Eisenberg as a self-taught project\n",
    "#\n",
    "#    Everybody - It will be super cool if you find some way to make the network \n",
    "#   work better. Enjoy\n",
    "#\n",
    "####################################################################################\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "TRAIN_PATH = \"/home/evilberg/Documents/Malaria Project/Data/Train/\"\n",
    "TEST_PATH = \"/home/evilberg/Documents/Malaria Project/Data/Test/\"\n",
    "VALIDATION_PATH = \"/home/evilberg/Documents/Malaria Project/Data/Validation/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing\n",
    "## Normalizing the data found better on original variance than unit variance\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((32, 32)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.1395, 0.2531, 0.3396], [1, 1, 1])])  \n",
    "\n",
    "train_data = datasets.ImageFolder(root=TRAIN_PATH,\n",
    "                                  transform=transform)\n",
    "\n",
    "test_data = datasets.ImageFolder(root=TEST_PATH,\n",
    "                                  transform=transform)\n",
    "\n",
    "val_data = datasets.ImageFolder(root=VALIDATION_PATH, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                             batch_size=2,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=2)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_data,\n",
    "                                          batch_size=2,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=2)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_data,\n",
    "                                          batch_size=2,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=2)\n",
    "\n",
    "classes = ('Parasitized', 'Uninfected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the network\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation : y = Wx + b\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.elu(self.conv1(x)))\n",
    "        x = self.pool(F.elu(self.conv2(x)))\n",
    "        x = x.view(-1, 16*5*5)\n",
    "        x = F.elu(self.fc1(x))\n",
    "        x = F.elu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=2, bias=True)\n",
      ")\n",
      "('len of param: ', 10)\n",
      "[1, 200], Loss: 1.39150323212\n",
      "[1, 400], Loss: 1.36806358844\n",
      "[1, 600], Loss: 1.37107931495\n",
      "[1, 800], Loss: 1.33920432895\n",
      "[1, 1000], Loss: 1.34845977813\n",
      "[1, 1200], Loss: 1.31294670373\n",
      "[1, 1400], Loss: 1.34555169165\n",
      "[1, 1600], Loss: 1.34662138909\n",
      "[1, 1800], Loss: 1.24064220279\n",
      "[1, 2000], Loss: 1.2772927317\n",
      "[1, 2200], Loss: 1.2591595912\n",
      "[1, 2400], Loss: 1.29976348355\n",
      "[1, 2600], Loss: 1.27086585015\n",
      "[1, 2800], Loss: 1.29115883827\n",
      "[1, 3000], Loss: 1.19821534872\n",
      "[1, 3200], Loss: 1.19208962157\n",
      "[1, 3400], Loss: 1.1654206492\n",
      "[1, 3600], Loss: 1.09754492819\n",
      "[1, 3800], Loss: 1.07714382455\n",
      "[1, 4000], Loss: 1.03317544132\n",
      "[1, 4200], Loss: 1.1123777616\n",
      "[1, 4400], Loss: 0.993344440907\n",
      "[1, 4600], Loss: 0.925920141339\n",
      "[1, 4800], Loss: 0.850894451588\n",
      "[1, 5000], Loss: 0.801439376324\n",
      "[1, 5200], Loss: 0.629596272558\n",
      "[1, 5400], Loss: 0.684281988442\n",
      "[1, 5600], Loss: 0.654845675528\n",
      "[1, 5800], Loss: 0.525214907676\n",
      "[1, 6000], Loss: 0.648983284086\n",
      "[1, 6200], Loss: 0.58977384299\n",
      "[1, 6400], Loss: 0.797383752018\n",
      "[1, 6600], Loss: 0.866010300517\n",
      "[1, 6800], Loss: 0.480492172241\n",
      "[1, 7000], Loss: 0.533297920376\n",
      "[1, 7200], Loss: 0.404488821179\n",
      "[1, 7400], Loss: 0.500895239711\n",
      "[1, 7600], Loss: 0.613348977268\n",
      "[1, 7800], Loss: 0.585843868405\n",
      "[1, 8000], Loss: 0.942696833313\n",
      "[1, 8200], Loss: 0.606511681825\n",
      "[1, 8400], Loss: 0.643152143359\n",
      "[1, 8600], Loss: 0.719934896976\n",
      "[1, 8800], Loss: 0.516080503464\n",
      "[1, 9000], Loss: 0.473667601794\n",
      "[1, 9200], Loss: 0.50721519649\n",
      "[1, 9400], Loss: 0.41369399637\n",
      "[1, 9600], Loss: 0.387604340613\n",
      "[1, 9800], Loss: 0.609785320014\n",
      "[2, 200], Loss: 0.470693332702\n",
      "[2, 400], Loss: 0.31821151413\n",
      "[2, 600], Loss: 0.417498431057\n",
      "[2, 800], Loss: 0.349967118204\n",
      "[2, 1000], Loss: 0.469855534434\n",
      "[2, 1200], Loss: 0.500544192493\n",
      "[2, 1400], Loss: 0.437923526317\n",
      "[2, 1600], Loss: 0.459172722697\n",
      "[2, 1800], Loss: 0.317598873824\n",
      "[2, 2000], Loss: 0.453715427667\n",
      "[2, 2200], Loss: 0.497684710622\n",
      "[2, 2400], Loss: 0.465355235636\n",
      "[2, 2600], Loss: 0.579447530508\n",
      "[2, 2800], Loss: 0.388882819712\n",
      "[2, 3000], Loss: 0.371046320647\n",
      "[2, 3200], Loss: 0.387983659059\n",
      "[2, 3400], Loss: 0.455602843165\n",
      "[2, 3600], Loss: 0.379713516533\n",
      "[2, 3800], Loss: 0.244324185997\n",
      "[2, 4000], Loss: 0.414142428041\n",
      "[2, 4200], Loss: 0.46831515044\n",
      "[2, 4400], Loss: 0.385033311322\n",
      "[2, 4600], Loss: 0.367162438184\n",
      "[2, 4800], Loss: 0.360173549056\n",
      "[2, 5000], Loss: 0.300369213447\n",
      "[2, 5200], Loss: 0.447020484209\n",
      "[2, 5400], Loss: 0.490857287794\n",
      "[2, 5600], Loss: 0.443846032619\n",
      "[2, 5800], Loss: 0.430929022431\n",
      "[2, 6000], Loss: 0.386967304796\n",
      "[2, 6200], Loss: 0.537900809795\n",
      "[2, 6400], Loss: 0.295544089824\n",
      "[2, 6600], Loss: 0.384256807268\n",
      "[2, 6800], Loss: 0.405649178624\n",
      "[2, 7000], Loss: 0.361339248866\n",
      "[2, 7200], Loss: 0.303861518651\n",
      "[2, 7400], Loss: 0.530164649338\n",
      "[2, 7600], Loss: 0.427141112089\n",
      "[2, 7800], Loss: 0.406419962347\n",
      "[2, 8000], Loss: 0.406069694161\n",
      "[2, 8200], Loss: 0.460014924705\n",
      "[2, 8400], Loss: 0.386940937489\n",
      "[2, 8600], Loss: 0.495532252118\n",
      "[2, 8800], Loss: 0.369655646533\n",
      "[2, 9000], Loss: 0.335491438359\n",
      "[2, 9200], Loss: 0.248336877078\n",
      "[2, 9400], Loss: 0.458873557895\n",
      "[2, 9600], Loss: 0.464010857642\n",
      "[2, 9800], Loss: 0.324842906892\n",
      "[3, 200], Loss: 0.397900528163\n",
      "[3, 400], Loss: 0.414013968557\n",
      "[3, 600], Loss: 0.26915293321\n",
      "[3, 800], Loss: 0.28152129814\n",
      "[3, 1000], Loss: 0.586732249111\n",
      "[3, 1200], Loss: 0.35191864863\n",
      "[3, 1400], Loss: 0.430034026802\n",
      "[3, 1600], Loss: 0.444097530097\n",
      "[3, 1800], Loss: 0.585715988874\n",
      "[3, 2000], Loss: 0.338277987689\n",
      "[3, 2200], Loss: 0.351471362412\n",
      "[3, 2400], Loss: 0.315575502664\n",
      "[3, 2600], Loss: 0.360407129973\n",
      "[3, 2800], Loss: 0.421405522227\n",
      "[3, 3000], Loss: 0.375202093869\n",
      "[3, 3200], Loss: 0.458850573599\n",
      "[3, 3400], Loss: 0.235423381478\n",
      "[3, 3600], Loss: 0.412902240306\n",
      "[3, 3800], Loss: 0.346366646737\n",
      "[3, 4000], Loss: 0.436708046794\n",
      "[3, 4200], Loss: 0.320871697217\n",
      "[3, 4400], Loss: 0.299886561334\n",
      "[3, 4600], Loss: 0.26364919737\n",
      "[3, 4800], Loss: 0.307781215012\n",
      "[3, 5000], Loss: 0.294809681922\n",
      "[3, 5200], Loss: 0.369529848844\n",
      "[3, 5400], Loss: 0.434846387208\n",
      "[3, 5600], Loss: 0.342105965316\n",
      "[3, 5800], Loss: 0.331229603589\n",
      "[3, 6000], Loss: 0.401543515027\n",
      "[3, 6200], Loss: 0.31820862025\n",
      "[3, 6400], Loss: 0.27069765836\n",
      "[3, 6600], Loss: 0.288487363011\n",
      "[3, 6800], Loss: 0.283621657938\n",
      "[3, 7000], Loss: 0.288699066192\n",
      "[3, 7200], Loss: 0.277790384591\n",
      "[3, 7400], Loss: 0.317651119977\n",
      "[3, 7600], Loss: 0.228175928444\n",
      "[3, 7800], Loss: 0.389018987417\n",
      "[3, 8000], Loss: 0.294703326523\n",
      "[3, 8200], Loss: 0.390696201771\n",
      "[3, 8400], Loss: 0.469126363248\n",
      "[3, 8600], Loss: 0.430235190094\n",
      "[3, 8800], Loss: 0.421326361895\n",
      "[3, 9000], Loss: 0.292908448279\n",
      "[3, 9200], Loss: 0.26888831228\n",
      "[3, 9400], Loss: 0.264609351605\n",
      "[3, 9600], Loss: 0.423785368353\n",
      "[3, 9800], Loss: 0.204530438483\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "## Training the network\n",
    "\n",
    "net = ConvNet()\n",
    "\n",
    "print(net)\n",
    "param = list(net.parameters())\n",
    "print(\"len of param: \", len(param))\n",
    "\n",
    "\n",
    "criteria = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.005, momentum=0.9)\n",
    "\n",
    "for epoch in range(3):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the input\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criteria(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:  # print every 200 minibatches\n",
    "            print(\"[{}, {}], Loss: {}\".format(epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4700\n",
      "4962\n",
      "0.947198710198\n",
      "Accuracy of the network on 2481 test images: 94 %\n",
      "Accuracy of Parasitized : 95 %\n",
      "Accuracy of Uninfected : 93 %\n"
     ]
    }
   ],
   "source": [
    "## Testing\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "class_correct = list(0. for i in range(2))\n",
    "class_total = list(0. for i in range(2))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(2):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "print(correct)\n",
    "print(total)\n",
    "print(float(correct / total)\n",
    "            \n",
    "print('Accuracy of the network on %d test images: %d %%' % (len(test_loader),\n",
    "    100 * correct / total))\n",
    "\n",
    "for i in range(2):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2596\n",
      "2755\n",
      "0.942286751361\n"
     ]
    }
   ],
   "source": [
    "## validation\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "class_correct = list(0. for i in range(2))\n",
    "class_total = list(0. for i in range(2))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in val_loader:\n",
    "        image, labels = data\n",
    "        outputs = net(image)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "print(correct)\n",
    "print(total)\n",
    "print(float(correct) / total)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
